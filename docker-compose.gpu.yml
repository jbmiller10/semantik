# Docker Compose GPU override configuration
# Use this file to enable GPU support for Semantik services
#
# Usage: docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up -d
#
# Prerequisites:
# - NVIDIA Docker runtime installed (nvidia-docker2)
# - NVIDIA GPU drivers installed on host
# - Docker configured to use nvidia runtime

version: '3.8'

services:
  # Override vecpipe service to add GPU support
  vecpipe:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1  # Number of GPUs to use (or "all" for all GPUs)
              capabilities: [gpu]
    environment:
      # GPU-specific environment variables
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      # Override to disable mock embeddings when GPU is available
      - USE_MOCK_EMBEDDINGS=false
      # Use larger models with GPU acceleration
      - DEFAULT_EMBEDDING_MODEL=${GPU_EMBEDDING_MODEL:-BAAI/bge-large-en-v1.5}
      - DEFAULT_QUANTIZATION=${GPU_QUANTIZATION:-float32}

  # Override webui service for GPU-accelerated embedding jobs
  webui:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      # GPU-specific environment variables
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
      # Increased memory limits for GPU operations
      - MODEL_MAX_MEMORY_GB=${MODEL_MAX_MEMORY_GB:-8}
      # Enable GPU memory monitoring
      - MONITOR_GPU_MEMORY=true