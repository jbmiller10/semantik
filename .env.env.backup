# Docker Environment Configuration for Semantik
# Copy this file to .env and update with your values

# -- Authentication Configuration --
# IMPORTANT: This will be automatically generated when using 'make docker-up'
# To manually generate: openssl rand -hex 32
JWT_SECRET_KEY=60263fd2a9c021676852e76eb014c51f06689dda55175ae9c5c3a279d5c19e9f
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# -- Embedding Model Configuration --
# Model settings are the same for both GPU and CPU deployments
USE_MOCK_EMBEDDINGS=false
DEFAULT_EMBEDDING_MODEL=Qwen/Qwen3-Embedding-0.6B

# -- Quantization Options --
# float32: Full precision (CPU/GPU, highest quality, most memory)
# float16: Half precision (GPU only, good quality, 50% less memory)
# int8: 8-bit quantization (GPU only with CUDA build, 75% less memory)
#
# IMPORTANT: For int8 quantization, you MUST use the CUDA-enabled build:
# docker compose -f docker-compose.yml -f docker-compose.cuda.yml up -d --build
#
# Memory usage examples for Qwen3-Embedding-0.6B:
# - float32: ~2.4GB VRAM
# - float16: ~1.2GB VRAM (recommended for most GPUs)
# - int8: ~0.6GB VRAM (requires CUDA build)
DEFAULT_QUANTIZATION=float16

# -- Qdrant Configuration --
# These are set automatically by docker-compose for inter-container communication
# Only override if using an external Qdrant instance
# QDRANT_HOST=qdrant
# QDRANT_PORT=6333
DEFAULT_COLLECTION=work_docs

# -- Document Processing Paths --
# Path on host machine containing documents to process
# This will be mounted read-only into the container
DOCUMENT_PATH=/home/states/Organizing + Training/Relational

# -- Service Configuration --
# Number of worker processes for the WebUI (adjust based on CPU cores)
WEBUI_WORKERS=auto

# -- GPU Configuration --
# Default configuration uses GPU acceleration
# Set which GPU to use (0 = first GPU, 1 = second GPU, etc.)
CUDA_VISIBLE_DEVICES=0
# GPU memory limit in GB
MODEL_MAX_MEMORY_GB=24

# -- Logging Configuration --
# Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# -- Rate Limiting (Optional) --
# API rate limiting configuration
# RATE_LIMIT_PER_MINUTE=60

# -- External Services (Optional) --
# If using external reranking service
# RERANKER_API_URL=
# RERANKER_API_KEY=

# -- Model Storage Configuration --
# Directory on host machine for persistent HuggingFace model storage
# Models will be downloaded once and reused across container restarts
HF_CACHE_DIR=./models

# Enable offline mode after models are downloaded to prevent rate limiting
# Set to true after initial model download to use only cached models
HF_HUB_OFFLINE=false