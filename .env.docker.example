# Docker Environment Configuration for Semantik
# Copy this file to .env and update with your values

# -- Authentication Configuration --
# IMPORTANT: docker-compose now enforces these values; replace the placeholders before starting.
# This will be automatically generated when using 'make docker-up'
# To manually generate: openssl rand -hex 32
JWT_SECRET_KEY=CHANGE_THIS_TO_A_STRONG_SECRET_KEY
ACCESS_TOKEN_EXPIRE_MINUTES=1440
FLOWER_USERNAME=replace-me-with-flower-user
FLOWER_PASSWORD=replace-me-with-strong-flower-password

# -- Connector Secrets Encryption --
# Fernet key for encrypting connector credentials (passwords, tokens, SSH keys)
# To generate: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# Or use: uv run python scripts/generate_secrets_key.py
CONNECTOR_SECRETS_KEY=CHANGE_THIS_TO_A_FERNET_KEY

# -- CORS Configuration --
# Comma-separated list of allowed origins for frontend development
# Default: http://localhost:5173,http://127.0.0.1:5173 (Vite default port)
# Example: http://localhost:3000,http://localhost:5173,https://myapp.com
# SECURITY WARNING: Never use '*' or 'null' - always specify exact origins
# CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# -- Embedding Model Configuration --
# Model settings are the same for both GPU and CPU deployments
USE_MOCK_EMBEDDINGS=false
DEFAULT_EMBEDDING_MODEL=Qwen/Qwen3-Embedding-0.6B

# -- Plugin Loading --
# External plugins load via `semantik.plugins` entry points.
# Global toggle (default: true):
# SEMANTIK_ENABLE_PLUGINS=true
# Per-type toggles (default: true):
# SEMANTIK_ENABLE_EMBEDDING_PLUGINS=true
# SEMANTIK_ENABLE_CHUNKING_PLUGINS=true
# SEMANTIK_ENABLE_CONNECTOR_PLUGINS=true

# -- Quantization Options --
# float32: Full precision (CPU/GPU, highest quality, most memory)
# float16: Half precision (GPU only, good quality, 50% less memory)
# int8: 8-bit quantization (GPU only, 75% less memory)
#
# NOTE: INT8 quantization now works with both standard and CUDA builds.
# For optimal GPU performance, the CUDA build is still recommended:
# docker compose -f docker-compose.yml -f docker-compose.cuda.yml up -d --build
#
# Memory usage examples for Qwen3-Embedding-0.6B:
# - float32: ~2.4GB VRAM
# - float16: ~1.2GB VRAM (recommended for most GPUs)
# - int8: ~0.6GB VRAM (requires CUDA build)
DEFAULT_QUANTIZATION=float16

# -- Local LLM Configuration --
# Local LLMs are GPU-intensive and require CUDA for practical performance.
# Disable if you don't have a compatible NVIDIA GPU.
ENABLE_LOCAL_LLM=true
# Default quantization for local LLMs (int4, int8, float16)
DEFAULT_LLM_QUANTIZATION=int8
# Idle timeout before unloading local LLM models (seconds)
LLM_UNLOAD_AFTER_SECONDS=300
# KV cache + runtime buffer per loaded LLM (MB)
LLM_KV_CACHE_BUFFER_MB=1024
# Allow models that require remote code
LLM_TRUST_REMOTE_CODE=false

# -- PostgreSQL Configuration (Optional - for PostgreSQL deployment) --
# Database URL - if set, overrides individual connection parameters
# For Docker, use the container name as host
# DATABASE_URL=postgresql://semantik:password@postgres:5432/semantik

# Individual PostgreSQL connection parameters
# Use these with docker-compose.postgres.yml
# POSTGRES_HOST=postgres       # Container name from docker-compose
# POSTGRES_PORT=5432
# POSTGRES_DB=semantik
# POSTGRES_USER=semantik
# POSTGRES_PASSWORD must be set before docker-compose can start (no insecure defaults).
POSTGRES_PASSWORD=CHANGE_THIS_TO_A_STRONG_PASSWORD

# -- Redis Configuration --
# Redis password for authentication (auto-generated by wizard)
# To manually generate: openssl rand -hex 32
REDIS_PASSWORD=CHANGE_THIS_TO_A_STRONG_PASSWORD

# PostgreSQL connection pool settings
# DB_POOL_SIZE=20              # Connection pool size
# DB_MAX_OVERFLOW=40           # Maximum overflow connections
# DB_POOL_TIMEOUT=30           # Pool timeout in seconds
# DB_POOL_RECYCLE=3600         # Connection recycle time in seconds
# DB_POOL_PRE_PING=true        # Test connections before use
# DB_IDLE_IN_TX_TIMEOUT_MS=60000 # Idle-in-transaction timeout (ms). Set > embed time or 0 to disable
DB_IDLE_IN_TX_TIMEOUT_MS=300000

# -- Qdrant Configuration --
# These are set automatically by docker-compose for inter-container communication
# Only override if using an external Qdrant instance
# QDRANT_HOST=qdrant
# QDRANT_PORT=6333
DEFAULT_COLLECTION=work_docs

# Qdrant API key for authentication (auto-generated by wizard)
# To manually generate: openssl rand -hex 32
QDRANT_API_KEY=CHANGE_THIS_TO_A_STRONG_API_KEY

# -- Document Processing Paths --
# Path on host machine containing documents to process
# This will be mounted read-only into the container
DOCUMENT_PATH=./documents

# -- Service Configuration --
# Number of worker processes for the WebUI (adjust based on CPU cores)
WEBUI_WORKERS=1

# -- Resource Limits --
# Maximum collections per user (default: 10)
# MAX_COLLECTIONS_PER_USER=10
# Maximum storage per user in GB (default: 50.0)
# MAX_STORAGE_GB_PER_USER=50.0

# -- Cache Settings --
# Default cache TTL in seconds (default: 300)
# CACHE_DEFAULT_TTL_SECONDS=300

# -- Background Cleanup Circuit Breaker --
# Cleanup interval in seconds (default: 60)
# REDIS_CLEANUP_INTERVAL_SECONDS=60
# Max consecutive failures before circuit opens (default: 5)
# REDIS_CLEANUP_MAX_CONSECUTIVE_FAILURES=5
# Backoff multiplier after circuit opens (default: 2.0)
# REDIS_CLEANUP_BACKOFF_MULTIPLIER=2.0
# Maximum backoff in seconds (default: 300)
# REDIS_CLEANUP_MAX_BACKOFF_SECONDS=300

# -- GPU Configuration --
# Default configuration uses GPU acceleration
# Set which GPU to use (0 = first GPU, 1 = second GPU, etc.)
CUDA_VISIBLE_DEVICES=0
# GPU memory limit in GB
MODEL_MAX_MEMORY_GB=8

# -- GPU Memory Governor Settings --
# Enable dynamic memory management with LRU eviction and CPU offloading
# ENABLE_MEMORY_GOVERNOR=true

# Memory Limits
# GPU_MEMORY_MAX_PERCENT=0.90        # Maximum GPU memory the application can use (default: 90%)
# CPU_MEMORY_MAX_PERCENT=0.50        # Maximum CPU memory for warm models (default: 50%)

# CPU Offloading
# When enabled, models are moved to CPU RAM instead of fully unloading
# This allows faster restoration (2-5s vs 10-30s reload from disk)
# ENABLE_CPU_OFFLOAD=true

# Eviction Behavior
# EVICTION_IDLE_THRESHOLD_SECONDS=120    # Idle time before model eligible for eviction
# PRESSURE_CHECK_INTERVAL_SECONDS=15     # Background pressure check interval

# Recommended configurations:
# - 24GB+ VRAM: Default settings work well, both models can coexist
# - 16GB VRAM: Default settings, may need occasional eviction under heavy load
# - 8GB VRAM: Consider GPU_MEMORY_MAX_PERCENT=0.85, shorter eviction threshold

# -- Logging Configuration --
# Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# -- Rate Limiting (Optional) --
# API rate limiting configuration
# RATE_LIMIT_PER_MINUTE=60

# -- External Services (Optional) --
# If using external reranking service
# RERANKER_API_URL=
# RERANKER_API_KEY=

# -- Model Storage Configuration --
# Directory on host machine for persistent HuggingFace model storage
# Models will be downloaded once and reused across container restarts
HF_CACHE_DIR=./models

# Enable offline mode after models are downloaded to prevent rate limiting
# Set to true after initial model download to use only cached models
HF_HUB_OFFLINE=false
